{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "dir = \"C:/Users/evani/OneDrive/AI leiden/Sanquin/RL_matching-main/NN training data/1_1/states\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "['states_0_0.pickle',\n 'states_0_1.pickle',\n 'states_0_10.pickle',\n 'states_0_11.pickle',\n 'states_0_12.pickle',\n 'states_0_2.pickle',\n 'states_0_3.pickle',\n 'states_0_4.pickle',\n 'states_0_5.pickle',\n 'states_0_6.pickle',\n 'states_0_7.pickle',\n 'states_0_8.pickle',\n 'states_0_9.pickle',\n 'states_10_0.pickle',\n 'states_10_1.pickle',\n 'states_10_10.pickle',\n 'states_10_11.pickle',\n 'states_10_12.pickle',\n 'states_10_2.pickle',\n 'states_10_3.pickle',\n 'states_10_4.pickle',\n 'states_10_5.pickle',\n 'states_10_6.pickle',\n 'states_10_7.pickle',\n 'states_10_8.pickle',\n 'states_10_9.pickle',\n 'states_11_0.pickle',\n 'states_11_1.pickle',\n 'states_11_10.pickle',\n 'states_11_11.pickle',\n 'states_11_12.pickle',\n 'states_11_2.pickle',\n 'states_11_3.pickle',\n 'states_11_4.pickle',\n 'states_11_5.pickle',\n 'states_11_6.pickle',\n 'states_11_7.pickle',\n 'states_11_8.pickle',\n 'states_11_9.pickle',\n 'states_12_0.pickle',\n 'states_12_1.pickle',\n 'states_12_10.pickle',\n 'states_12_11.pickle',\n 'states_12_12.pickle',\n 'states_12_2.pickle',\n 'states_12_3.pickle',\n 'states_12_4.pickle',\n 'states_12_5.pickle',\n 'states_12_6.pickle',\n 'states_12_7.pickle',\n 'states_12_8.pickle',\n 'states_12_9.pickle',\n 'states_13_0.pickle',\n 'states_13_1.pickle',\n 'states_13_10.pickle',\n 'states_13_11.pickle',\n 'states_13_12.pickle',\n 'states_13_2.pickle',\n 'states_13_3.pickle',\n 'states_13_4.pickle',\n 'states_13_5.pickle',\n 'states_13_6.pickle',\n 'states_13_7.pickle',\n 'states_13_8.pickle',\n 'states_13_9.pickle',\n 'states_14_0.pickle',\n 'states_14_1.pickle',\n 'states_14_10.pickle',\n 'states_14_11.pickle',\n 'states_14_12.pickle',\n 'states_14_2.pickle',\n 'states_14_3.pickle',\n 'states_14_4.pickle',\n 'states_14_5.pickle',\n 'states_14_6.pickle',\n 'states_14_7.pickle',\n 'states_14_8.pickle',\n 'states_14_9.pickle',\n 'states_15_0.pickle',\n 'states_15_1.pickle',\n 'states_15_10.pickle',\n 'states_15_11.pickle',\n 'states_15_12.pickle',\n 'states_15_2.pickle',\n 'states_15_3.pickle',\n 'states_15_4.pickle',\n 'states_15_5.pickle',\n 'states_15_6.pickle',\n 'states_15_7.pickle',\n 'states_15_8.pickle',\n 'states_15_9.pickle',\n 'states_16_0.pickle',\n 'states_16_1.pickle',\n 'states_16_10.pickle',\n 'states_16_11.pickle',\n 'states_16_12.pickle',\n 'states_16_2.pickle',\n 'states_16_3.pickle',\n 'states_16_4.pickle',\n 'states_16_5.pickle',\n 'states_16_6.pickle',\n 'states_16_7.pickle',\n 'states_16_8.pickle',\n 'states_16_9.pickle',\n 'states_17_0.pickle',\n 'states_17_1.pickle',\n 'states_17_10.pickle',\n 'states_17_11.pickle',\n 'states_17_12.pickle',\n 'states_17_2.pickle',\n 'states_17_3.pickle',\n 'states_17_4.pickle',\n 'states_17_5.pickle',\n 'states_17_6.pickle',\n 'states_17_7.pickle',\n 'states_17_8.pickle',\n 'states_17_9.pickle',\n 'states_18_0.pickle',\n 'states_18_1.pickle',\n 'states_18_10.pickle',\n 'states_18_11.pickle',\n 'states_18_12.pickle',\n 'states_18_2.pickle',\n 'states_18_3.pickle',\n 'states_18_4.pickle',\n 'states_18_5.pickle',\n 'states_18_6.pickle',\n 'states_18_7.pickle',\n 'states_18_8.pickle',\n 'states_18_9.pickle',\n 'states_19_0.pickle',\n 'states_19_1.pickle',\n 'states_19_10.pickle',\n 'states_19_11.pickle',\n 'states_19_12.pickle',\n 'states_19_2.pickle',\n 'states_19_3.pickle',\n 'states_19_4.pickle',\n 'states_19_5.pickle',\n 'states_19_6.pickle',\n 'states_19_7.pickle',\n 'states_19_8.pickle',\n 'states_19_9.pickle',\n 'states_1_0.pickle',\n 'states_1_1.pickle',\n 'states_1_10.pickle',\n 'states_1_11.pickle',\n 'states_1_12.pickle',\n 'states_1_2.pickle',\n 'states_1_3.pickle',\n 'states_1_4.pickle',\n 'states_1_5.pickle',\n 'states_1_6.pickle',\n 'states_1_7.pickle',\n 'states_1_8.pickle',\n 'states_1_9.pickle',\n 'states_20_0.pickle',\n 'states_20_1.pickle',\n 'states_20_10.pickle',\n 'states_20_11.pickle',\n 'states_20_12.pickle',\n 'states_20_2.pickle',\n 'states_20_3.pickle',\n 'states_20_4.pickle',\n 'states_20_5.pickle',\n 'states_20_6.pickle',\n 'states_20_7.pickle',\n 'states_20_8.pickle',\n 'states_20_9.pickle',\n 'states_21_0.pickle',\n 'states_21_1.pickle',\n 'states_21_10.pickle',\n 'states_21_11.pickle',\n 'states_21_12.pickle',\n 'states_21_2.pickle',\n 'states_21_3.pickle',\n 'states_21_4.pickle',\n 'states_21_5.pickle',\n 'states_21_6.pickle',\n 'states_21_7.pickle',\n 'states_21_8.pickle',\n 'states_21_9.pickle',\n 'states_22_0.pickle',\n 'states_22_1.pickle',\n 'states_22_10.pickle',\n 'states_22_11.pickle',\n 'states_22_12.pickle',\n 'states_22_2.pickle',\n 'states_22_3.pickle',\n 'states_22_4.pickle',\n 'states_22_5.pickle',\n 'states_22_6.pickle',\n 'states_22_7.pickle',\n 'states_22_8.pickle',\n 'states_22_9.pickle',\n 'states_23_0.pickle',\n 'states_23_1.pickle',\n 'states_23_10.pickle',\n 'states_23_11.pickle',\n 'states_23_12.pickle',\n 'states_23_2.pickle',\n 'states_23_3.pickle',\n 'states_23_4.pickle',\n 'states_23_5.pickle',\n 'states_23_6.pickle',\n 'states_23_7.pickle',\n 'states_23_8.pickle',\n 'states_23_9.pickle',\n 'states_24_0.pickle',\n 'states_24_1.pickle',\n 'states_24_10.pickle',\n 'states_24_11.pickle',\n 'states_24_12.pickle',\n 'states_24_2.pickle',\n 'states_24_3.pickle',\n 'states_24_4.pickle',\n 'states_24_5.pickle',\n 'states_24_6.pickle',\n 'states_24_7.pickle',\n 'states_24_8.pickle',\n 'states_24_9.pickle',\n 'states_2_0.pickle',\n 'states_2_1.pickle',\n 'states_2_10.pickle',\n 'states_2_11.pickle',\n 'states_2_12.pickle',\n 'states_2_2.pickle',\n 'states_2_3.pickle',\n 'states_2_4.pickle',\n 'states_2_5.pickle',\n 'states_2_6.pickle',\n 'states_2_7.pickle',\n 'states_2_8.pickle',\n 'states_2_9.pickle',\n 'states_3_0.pickle',\n 'states_3_1.pickle',\n 'states_3_10.pickle',\n 'states_3_11.pickle',\n 'states_3_12.pickle',\n 'states_3_2.pickle',\n 'states_3_3.pickle',\n 'states_3_4.pickle',\n 'states_3_5.pickle',\n 'states_3_6.pickle',\n 'states_3_7.pickle',\n 'states_3_8.pickle',\n 'states_3_9.pickle',\n 'states_4_0.pickle',\n 'states_4_1.pickle',\n 'states_4_10.pickle',\n 'states_4_11.pickle',\n 'states_4_12.pickle',\n 'states_4_2.pickle',\n 'states_4_3.pickle',\n 'states_4_4.pickle',\n 'states_4_5.pickle',\n 'states_4_6.pickle',\n 'states_4_7.pickle',\n 'states_4_8.pickle',\n 'states_4_9.pickle',\n 'states_5_0.pickle',\n 'states_5_1.pickle',\n 'states_5_10.pickle',\n 'states_5_11.pickle',\n 'states_5_12.pickle',\n 'states_5_2.pickle',\n 'states_5_3.pickle',\n 'states_5_4.pickle',\n 'states_5_5.pickle',\n 'states_5_6.pickle',\n 'states_5_7.pickle',\n 'states_5_8.pickle',\n 'states_5_9.pickle',\n 'states_6_0.pickle',\n 'states_6_1.pickle',\n 'states_6_10.pickle',\n 'states_6_11.pickle',\n 'states_6_12.pickle',\n 'states_6_2.pickle',\n 'states_6_3.pickle',\n 'states_6_4.pickle',\n 'states_6_5.pickle',\n 'states_6_6.pickle',\n 'states_6_7.pickle',\n 'states_6_8.pickle',\n 'states_6_9.pickle',\n 'states_7_0.pickle',\n 'states_7_1.pickle',\n 'states_7_10.pickle',\n 'states_7_11.pickle',\n 'states_7_12.pickle',\n 'states_7_2.pickle',\n 'states_7_3.pickle',\n 'states_7_4.pickle',\n 'states_7_5.pickle',\n 'states_7_6.pickle',\n 'states_7_7.pickle',\n 'states_7_8.pickle',\n 'states_7_9.pickle',\n 'states_8_0.pickle',\n 'states_8_1.pickle',\n 'states_8_10.pickle',\n 'states_8_11.pickle',\n 'states_8_12.pickle',\n 'states_8_2.pickle',\n 'states_8_3.pickle',\n 'states_8_4.pickle',\n 'states_8_5.pickle',\n 'states_8_6.pickle',\n 'states_8_7.pickle',\n 'states_8_8.pickle',\n 'states_8_9.pickle',\n 'states_9_0.pickle',\n 'states_9_1.pickle',\n 'states_9_10.pickle',\n 'states_9_11.pickle',\n 'states_9_12.pickle',\n 'states_9_2.pickle',\n 'states_9_3.pickle',\n 'states_9_4.pickle',\n 'states_9_5.pickle',\n 'states_9_6.pickle',\n 'states_9_7.pickle',\n 'states_9_8.pickle',\n 'states_9_9.pickle']"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "array_list = []\n",
    "for file in os.listdir(dir):\n",
    "    f = os.path.join(dir, file)\n",
    "    states = np.load(f, allow_pickle=True)\n",
    "    array_list.append(states)\n",
    "\n",
    "full = np.vstack(array_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "1143224"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([63., 63., 63., ..., 50., 50., 50.])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[:, 3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:  0\n",
      "1st:  0.0\n",
      "99th:  30.0\n",
      "# outliers:  8318\n",
      "column:  1\n",
      "1st:  0.0\n",
      "99th:  7.0\n",
      "# outliers:  8244\n",
      "column:  2\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n",
      "column:  3\n",
      "1st:  3.0\n",
      "99th:  65.0\n",
      "# outliers:  19371\n",
      "column:  4\n",
      "1st:  0.0\n",
      "99th:  45.0\n",
      "# outliers:  11088\n",
      "column:  5\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n",
      "column:  6\n",
      "1st:  0.0\n",
      "99th:  6.0\n",
      "# outliers:  6594\n",
      "column:  7\n",
      "1st:  0.0\n",
      "99th:  5.0\n",
      "# outliers:  10012\n",
      "column:  8\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n",
      "column:  9\n",
      "1st:  0.0\n",
      "99th:  16.0\n",
      "# outliers:  7718\n",
      "column:  10\n",
      "1st:  0.0\n",
      "99th:  16.0\n",
      "# outliers:  8916\n",
      "column:  11\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n",
      "column:  12\n",
      "1st:  0.0\n",
      "99th:  18.0\n",
      "# outliers:  6174\n",
      "column:  13\n",
      "1st:  0.0\n",
      "99th:  15.0\n",
      "# outliers:  10857\n",
      "column:  14\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n",
      "column:  15\n",
      "1st:  9.0\n",
      "99th:  59.0\n",
      "# outliers:  19942\n",
      "column:  16\n",
      "1st:  0.0\n",
      "99th:  58.0\n",
      "# outliers:  11391\n",
      "column:  17\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n",
      "column:  18\n",
      "1st:  0.0\n",
      "99th:  3.0\n",
      "# outliers:  7103\n",
      "column:  19\n",
      "1st:  0.0\n",
      "99th:  4.0\n",
      "# outliers:  8798\n",
      "column:  20\n",
      "1st:  0.0\n",
      "99th:  0.0\n",
      "# outliers:  7640\n",
      "column:  21\n",
      "1st:  0.0\n",
      "99th:  6.0\n",
      "# outliers:  5376\n",
      "column:  22\n",
      "1st:  0.0\n",
      "99th:  10.0\n",
      "# outliers:  8982\n",
      "column:  23\n",
      "1st:  0.0\n",
      "99th:  1.0\n",
      "# outliers:  0\n"
     ]
    }
   ],
   "source": [
    "for c in range(full.shape[1]):\n",
    "    first = np.percentile(full[:, c], 1)\n",
    "    nn = np.percentile(full[:, c], 99)\n",
    "    outliers = []\n",
    "    for x in full[:, c]:\n",
    "        if x < first or x > nn:\n",
    "            outliers.append(x)\n",
    "\n",
    "    print('column: ', c)\n",
    "    print('1st: ', first)\n",
    "    print('99th: ', nn)\n",
    "    print('# outliers: ', len(outliers))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[28.,  6.,  1., ...,  3.,  7.,  0.],\n       [27.,  5.,  1., ...,  3.,  7.,  0.],\n       [26.,  4.,  1., ...,  3.,  7.,  0.],\n       ...,\n       [ 6.,  0.,  0., ...,  3.,  2.,  0.],\n       [ 6.,  0.,  0., ...,  2.,  1.,  1.],\n       [ 6.,  0.,  0., ...,  2.,  0.,  1.]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[np.where(full[:, 18] > 5)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "9726"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(full[:, 3] < 3)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "y = np.nonzero(matrix == 1)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "array([12.61694996, 36.53002386,  2.1517218 ,  6.16659552,  8.85530745,\n       32.70347718,  0.34498926,  0.63093497])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)[1] / len(y) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "subset_indices, _ = train_test_split(\n",
    "    range(len(y)),\n",
    "    stratify=y,\n",
    "    train_size=0.1,\n",
    ")\n",
    "\n",
    "# Split 80/20 for training and validation\n",
    "train_set, val_set = train_test_split(\n",
    "    subset_indices,\n",
    "    stratify=y[subset_indices],\n",
    "    test_size=0.2,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "train = y[train_set]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "array([12.6168582 , 36.52973529,  2.15183092,  6.1668325 ,  8.85552773,\n       32.70389363,  0.34442416,  0.63089758])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train, return_counts=True)[1] / len(train) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = (matrix == 1).nonzero()[:, 1]\n",
    "\n",
    "subset_indices = train_test_split(\n",
    "    range(len(matrix)),\n",
    "    stratify=y,\n",
    "    train_size=0.1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "feature_indices = []\n",
    "for i in range(24):\n",
    "    if i % 3 == 0:\n",
    "        feature_indices.append(i)\n",
    "        feature_indices.append(i + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.randint(0, 100, (5,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(22)"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[3,]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def normalize(matrix):\n",
    "    columns = matrix.shape[1]\n",
    "    feature_indices = [(i, i + 1) for i in range(columns) if (i % 3 == 0)]\n",
    "    min_max = []\n",
    "\n",
    "    for i in feature_indices:\n",
    "        min_max.append((np.min(matrix[:, i[0]]), np.max(matrix[:, i[0]])))\n",
    "        min_max.append((np.min(matrix[:, i[1]]), np.max(matrix[:, i[1]])))\n",
    "\n",
    "    for i in range(len(matrix)):\n",
    "        index = 0\n",
    "        for j in feature_indices:\n",
    "            matrix[i, j[0]] = (\n",
    "                    (matrix[i, j[0]] - min_max[index][0]) / (min_max[index][1] - min_max[index][0]))\n",
    "            matrix[i, j[1]] = (\n",
    "                    (matrix[i, j[1]] - min_max[index + 1][0]) / (min_max[index + 1][1] - min_max[index + 1][0]))\n",
    "            index += 2\n",
    "    return matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.45454545, 0.11538462, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       [0.43181818, 0.07692308, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       [0.40909091, 0.03846154, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       ...,\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.11764706,\n        1.        ],\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.05882353,\n        1.        ],\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.        ,\n        1.        ]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "targets = \"C:/Users/evani/OneDrive/AI leiden/Sanquin/RL_matching-main/NN training data/1_1/q_matrices\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "array_list = []\n",
    "for file in os.listdir(targets):\n",
    "    f = os.path.join(targets, file)\n",
    "    states = np.load(f, allow_pickle=True)\n",
    "    array_list.append(states)\n",
    "\n",
    "y = np.vstack(array_list)\n",
    "y = torch.from_numpy(y).long()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def weighted_sampler(y):\n",
    "    class_counts = torch.sum(y, dim=0)\n",
    "    class_weights = 1. / class_counts\n",
    "    class_weights_all = class_weights[y]\n",
    "\n",
    "    # weighted_sampler = WeightedRandomSampler(\n",
    "    #     weights=class_weights_all,\n",
    "    #     num_samples=len(class_weights_all),\n",
    "    #     replacement=True\n",
    "    # )\n",
    "\n",
    "    # return weighted_sampler\n",
    "\n",
    "    return class_weights_all, class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([144240, 417620,  24599,  70498, 101236, 373874,   3944,   7213])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "weights, counts = weighted_sampler(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 4, 4])"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "indices = (y == 1).nonzero()[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, data_path=None, target_path=None):\n",
    "        train_list = []\n",
    "        for i in os.listdir(data_path):\n",
    "            data = np.load(data_path + i, allow_pickle=True)\n",
    "            train_list.append(data)\n",
    "\n",
    "        test_list = []\n",
    "        for i in os.listdir(target_path):\n",
    "            data = np.load(target_path + i, allow_pickle=True)\n",
    "            test_list.append(data)\n",
    "\n",
    "        self.x = torch.from_numpy(np.vstack(train_list)).float()\n",
    "        self.y = torch.from_numpy(np.vstack(test_list)).float()\n",
    "        self.y = (self.y == 1).nonzero()[:, 1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.x[idx], self.y[idx]\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "data_path = 'NN training data/1_1/states/'\n",
    "target_path = 'NN training data/1_1/q_matrices/'\n",
    "\n",
    "dataset = MyData(data_path, target_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "targets = dataset.y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([144240, 417620,  24599,  70498, 101236, 373874,   3944,   7213])"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(targets, return_counts=True)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "class_counts = torch.unique(targets, return_counts=True)[1]\n",
    "class_weights = 1. / class_counts\n",
    "class_weights_all = class_weights[targets]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([144240, 417620,  24599,  70498, 101236, 373874,   3944,   7213])"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([6.9329e-06, 2.3945e-06, 4.0652e-05, 1.4185e-05, 9.8779e-06, 2.6747e-06,\n        2.5355e-04, 1.3864e-04])"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. / class_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([6.9329e-06, 2.3945e-06, 4.0652e-05, 1.4185e-05, 9.8779e-06, 2.6747e-06,\n        2.5355e-04, 1.3864e-04])"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "y_pred = torch.rand(7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "y_pred = torch.tensor([[0.1453, -0.0590, -0.0065, 0.0905, 0.0146, -0.0805, -0.1211, -0.0394,\n",
    "                        -0.0181, -0.0136]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([-2.1513]),\nindices=tensor([0]))"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.log_softmax(y_pred, dim=1), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "loss = loss = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "target = torch.tensor([0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "y_pred = torch.tensor([[0.6, 0.4, 0.3, 0.22, 0.55]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.4338)"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y_pred, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "MinMaxScaler()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(full)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(full)\n",
    "scaled = scaler.transform(full)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.45454545, 0.11538462, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       [0.43181818, 0.07692308, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       [0.40909091, 0.03846154, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       ...,\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.11764706,\n        1.        ],\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.05882353,\n        1.        ],\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.        ,\n        1.        ]])"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}