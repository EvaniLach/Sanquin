CREATING ENVIRONMENT
CREATING DQN
alpha: 0.001, gamma: 0.99, batch size: 50.

Episode: 0
Day 0, reward -738.0
Day 1, reward -900.0
Day 2, reward -3000.0
Day 3, reward -2900.0
Traceback (most recent call last):
  File "/home/s1949624/RL_matching/experiments.py", line 50, in <module>
    main()
  File "/home/s1949624/RL_matching/experiments.py", line 46, in main
    dqn.train(SETTINGS, PARAMS)
  File "/home/s1949624/RL_matching/dqn_torch.py", line 177, in train
    action = self.select_action(state, limit, PARAMS)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1949624/RL_matching/dqn_torch.py", line 56, in select_action
    Qp = self.q_net(torch.from_numpy(state).flatten().float().cuda())
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
