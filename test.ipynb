{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dir = 'NN training data/1_1/states'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "feature_indices = [(i, i + 1) for i in range(24) if (i % 3 == 0)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, 1), (3, 4), (6, 7), (9, 10), (12, 13), (15, 16), (18, 19), (21, 22)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "f = np.load(dir + '/states_0_0.pickle', allow_pickle=True)\n",
    "f_b = f.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "max_r_list = [0] * 8\n",
    "max_i_list = [0] * 8\n",
    "episode = 0\n",
    "max_r = 0\n",
    "max_i = 0\n",
    "# for filename in os.listdir(dir):\n",
    "#     f = np.load(os.path.join(dir, filename), allow_pickle=True)\n",
    "bg = 0\n",
    "for i in feature_indices:\n",
    "    if np.amax(f[:, i[0]]) > max_r_list[bg]:\n",
    "        max_r_list[bg] = np.amax(f[:, i[0]])\n",
    "    if np.amax(f[:, i[1]]) > max_i_list[bg]:\n",
    "        max_i_list[bg] = np.amax(f[:, i[1]])\n",
    "    # if (episode > 0) and (episode % 13 == 0):\n",
    "    bg += 1\n",
    "# episode += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[35.0, 70.0, 7.0, 20.0, 20.0, 61.0, 4.0, 7.0]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_r_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "[15.0, 58.0, 5.0, 13.0, 14.0, 50.0, 4.0, 8.0]"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_i_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Check max amount of requests and inventory amount per episode to see if normalization is necessary\n",
    "max_r_list = []\n",
    "max_i_list = []\n",
    "file_r = ''\n",
    "file_i = ''\n",
    "j = 0\n",
    "max_r = 0\n",
    "max_i = 0\n",
    "for filename in os.listdir(dir):\n",
    "    f = np.load(os.path.join(dir, filename), allow_pickle=True)\n",
    "for i in range(24):\n",
    "    if\n",
    "i % 3 == 0:\n",
    "if np.amax(f[:, i]) > max_r:\n",
    "    max_r = np.amax(f[:, i])\n",
    "if np.amax(f[:, i + 1]) > max_i:\n",
    "    max_i = np.amax(f[:, i + 1])\n",
    "if (j > 0) and (j % 13 == 0):\n",
    "    max_r_list.append(max_r)\n",
    "max_i_list.append(max_i)\n",
    "max_r = 0\n",
    "max_i = 0\n",
    "j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_r_list = []\n",
    "max_i_list = []\n",
    "j = 0\n",
    "max_r = 0\n",
    "max_i = 0\n",
    "for filename in os.listdir(dir):\n",
    "    f = np.load(os.path.join(dir, filename), allow_pickle=True)\n",
    "for i in range(24):\n",
    "    if\n",
    "i % 3 == 0:\n",
    "if np.amax(f[:, i]) > max_r:\n",
    "    max_r = np.amax(f[:, i])\n",
    "if np.amax(f[:, i + 1]) > max_i:\n",
    "    max_i = np.amax(f[:, i + 1])\n",
    "if (j > 0) and (j % 13 == 0):\n",
    "    max_r_list.append(max_r)\n",
    "max_i_list.append(max_i)\n",
    "max_r = 0\n",
    "max_i = 0\n",
    "j += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "24"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max amount of requests per episode in any state\n",
    "len(max_r_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "[72.0,\n 91.0,\n 78.0,\n 70.0,\n 78.0,\n 83.0,\n 75.0,\n 72.0,\n 102.0,\n 82.0,\n 64.0,\n 64.0,\n 80.0,\n 77.0,\n 75.0,\n 78.0,\n 72.0,\n 90.0,\n 77.0,\n 76.0,\n 91.0,\n 75.0,\n 70.0,\n 71.0]"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max inventory of any blood group per episode in any state\n",
    "max_i_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "feature_indices = [(i, i + 1) for i in range(24) if (i % 3 == 0)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [],
   "source": [
    "matrix = np.load(dir + '/states_0_0.pickle', allow_pickle=True)\n",
    "matrix_b = matrix.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "dir = \"C:/Users/evani/OneDrive/AI leiden/Sanquin/RL_matching-main/NN training data/1_1/states\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "array_list = []\n",
    "for file in os.listdir(dir):\n",
    "    f = os.path.join(dir, file)\n",
    "    states = np.load(f, allow_pickle=True)\n",
    "    array_list.append(states)\n",
    "\n",
    "full = np.vstack(array_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "matrix = full.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "min_max = []\n",
    "\n",
    "for i in feature_indices:\n",
    "    min_max.append((np.amin(matrix[:, i[0]]), np.amax(matrix[:, i[0]])))\n",
    "    min_max.append((np.amin(matrix[:, i[1]]), np.amax(matrix[:, i[1]])))\n",
    "\n",
    "for i in range(len(matrix)):\n",
    "    index = 0\n",
    "    for j in feature_indices:\n",
    "        matrix[i, j[0]] = (\n",
    "                (matrix[i, j[0]] - min_max[index][0]) / (min_max[index][1] - min_max[index][0]))\n",
    "        matrix[i, j[1]] = (\n",
    "                (matrix[i, j[1]] - min_max[index + 1][0]) / (min_max[index + 1][1] - min_max[index + 1][0]))\n",
    "        index += 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.45454545, 0.11538462, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       [0.43181818, 0.07692308, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       [0.40909091, 0.03846154, 1.        , ..., 0.18181818, 0.        ,\n        0.        ],\n       ...,\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.11764706,\n        1.        ],\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.05882353,\n        1.        ],\n       [0.43181818, 0.        , 0.        , ..., 0.09090909, 0.        ,\n        1.        ]])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# create a 2D tensor of size (3, 4)\n",
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]])\n",
    "\n",
    "# select the element at position (1, 2)\n",
    "print(x[1, 2])  # output: tensor(7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}